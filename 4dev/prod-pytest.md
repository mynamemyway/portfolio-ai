*   **Автотесты:** Написать автотесты для проверки всей логики кроме внешних запросов к LLM.

### План разработки: Модуль автоматического тестирования

**Цель:** Интегрировать в проект фреймворк `pytest` и написать первый набор тестов для проверки корректности работы модуля сбора статистики. Это создаст основу для дальнейшего покрытия кода тестами.

---

**Этап 1: Настройка тестового окружения**
*   **Цель:** Установить и настроить фреймворк для тестирования.
*   **Действия:**
    1.  Добавить `pytest` и `pytest-asyncio` в файл зависимостей `requirements.txt`.
    2.  Создать директорию `tests/` в корне проекта для хранения всех тестов.
    3.  Создать пустой файл `__init__.py` в директории `tests/`

---

**Этап 2: Написание тестов для модуля `stats.py`**
*   **Цель:** Написать автотесты для функции `log_query`, проверяющие корректность записи данных в базу.
*   **Файл:** `tests/core/test_stats.py` (новый файл).
*   **Техническая логика:**
    1.  **Изоляция тестов:** Мы будем использовать `pytest fixture` для создания временной, изолированной базы данных SQLite в памяти для каждого теста. Это гарантирует, что тесты не влияют друг на друга и на основную рабочую базу данных.
    2.  **Тест полного логирования:** Будет написан асинхронный тест `test_log_query_full`, который вызывает `log_query` со всеми параметрами и проверяет корректность записи всех полей.
    3.  **Тест минимального логирования:** Будет написан асинхронный тест `test_log_query_minimal`, который вызывает `log_query` только с обязательными параметрами (имитируя клик) и проверяет, что опциональные поля записаны как `NULL`.

### План тестирования `app/core/memory.py`

**Цель:** Написать набор автотестов для класса `SQLiteChatMessageHistory`, чтобы убедиться в корректной работе всех операций с историей чата: добавление, извлечение и очистка сообщений.

**Техническая логика:**
Мы будем использовать тот же надежный подход, что и в `test_stats.py`, — создание временной файловой базы данных для каждого теста, чтобы гарантировать полную изоляцию.

1.  **Создание файла:** Создадим новый тестовый файл `tests/test_memory.py`.
2.  **Фикстура `isolated_db_path`:** Мы создадим аналогичную фикстуру, которая будет подменять путь к базе данных в модуле `app.core.memory` на путь к временному файлу.
3.  **Тесты:**
    *   **`test_add_and_retrieve_single_message`:** Проверит, что одно сообщение корректно добавляется и извлекается для конкретной сессии.
    *   **`test_add_and_retrieve_multiple_messages`:** Проверит, что пакетное добавление нескольких сообщений (`add_messages`) работает правильно.
    *   **`test_clear_history`:** Убедится, что метод `clear()` удаляет сообщения только для указанной сессии, не затрагивая другие.
    *   **`test_history_isolation_between_sessions`:** Ключевой тест, который проверит, что истории двух разных пользователей (`session_id`) в одной базе данных полностью изолированы друг от друга.
    *   **`test_non_ascii_characters`:** Проверит, что сообщения с кириллическими символами корректно сохраняются и извлекаются, подтверждая работу нашего исправления с `ensure_ascii=False`.


### План тестирования `app/handlers/user_handlers.py`

**Цель:** Написать модульные тесты для обработчиков команд и колбэков, изолируя их от внешних зависимостей (сеть, LLM) и проверяя корректность их реакции на действия пользователя.

**Техническая логика:**
Для этого нам понадобится новый инструмент — `aiogram-tests`, который позволяет создавать "моки" (mock objects) для объектов `aiogram` и отслеживать вызовы API бота.

1.  **Настройка окружения:**
    *   Добавить `aiogram-tests` в `requirements.txt`.
    *   Создать новый тестовый файл `tests/test_handlers.py`.

2.  **Создание фикстур:**
    *   **`bot`:** Фикстура, которая будет создавать мок-объект `Bot` с `MemoryStorage` и `Requester` для отслеживания исходящих запросов.
    *   **`dispatcher`:** Фикстура для создания экземпляра `Dispatcher`.
    *   **`db_path`:** Аналогичная фикстура, как и в предыдущих тестах, для создания временной файловой БД и подмены путей в модулях `stats` и `memory`.

3.  **Написание тестов:**
    *   **Тестирование команд (`/start`, `/help`, `/reset`):**
        *   **`test_start_command`:** Проверит, что по команде `/start` бот отправляет приветственное сообщение (`WELCOME_MESSAGE_TEXT`) и правильную клавиатуру. Также проверит, что в `query_stats` создается запись `COMMAND: /start`.
        *   **`test_reset_command`:** Проверит, что после добавления сообщений в историю команда `/reset` очищает историю для конкретного пользователя и отправляет подтверждение.
    *   **Тестирование обработки текстовых сообщений:**
        *   **`test_text_message_handler`:** Это самый сложный тест. Мы **полностью заблокируем** (`mock`) RAG-цепочку, чтобы она не делала реальных запросов к LLM. Вместо этого она будет мгновенно возвращать предопределенный ответ. Тест проверит, что:
            1.  Обработчик `handle_message` правильно вызывает RAG-цепь.
            2.  Ответ от "мок-цепи" корректно отправляется пользователю.
            3.  Вся информация (вопрос, мок-ответ, мок-контекст) правильно логируется в `query_stats`.
            4.  Диалог сохраняется в `chat_history`.
    *   **Тестирование `callback`-кнопок:**
        *   **`test_static_callback_handler`:** Проверит реакцию на статическую кнопку (например, "Projects"). Убедится, что бот редактирует сообщение и показывает нужную клавиатуру, а в `query_stats` появляется запись `CLICK: Projects Button`.
