# План Реализации: Шаг 2 - Создание и Индексирование Базы Знаний (RAG)

## Введение
Этот план описывает последовательность действий для создания и наполнения векторной базы знаний (RAG). Мы будем следовать принципу "снизу-вверх", сначала определяя и инициализируя все необходимые компоненты (модель эмбеддингов, векторная БД), а затем реализуя основную бизнес-логику, которая их использует.

---

## Подготовка:
1. Установить виртуальное окружение
2. Зависимости
3. Добавить пример рабочего модуля мистрал

---

### **Этап 1: Конфигурация и Инициализация Компонентов**

На этом этапе мы подготовим все строительные блоки для нашей системы индексации. Вся логика будет инкапсулирована в новом файле `app/core/rag.py`.

#### **1.1. Определение Констант и Путей**
*   **Цель:** Централизованно задать все необходимые пути и константы для легкой конфигурации и поддержки.
*   **Файл:** `app/core/rag.py`
*   **Логика:** В начале файла определить константы:
    *   `KNOWLEDGE_BASE_DIR`: Путь к директории `knowledge_base`.
    *   `CHROMA_PERSIST_DIR`: Путь к директории `chroma_db`, где будет храниться векторная база.
    *   `MISTRAL_EMBEDDING_MODEL`: Имя модели эмбеддингов от Mistral (например, `mistral-embed`).
    *   `HF_EMBEDDING_MODEL_NAME`: Имя модели для локальной векторизации из HuggingFace (например, `all-MiniLM-L6-v2`), используется как альтернатива.

#### **1.2. Инициализация Модели Эмбеддингов**
*   **Цель:** Создать объект модели для преобразования текста в векторы (эмбеддинги).
*   **Файл:** `app/core/rag.py`
*   **Логика (Основной вариант для продакшена):**
    1.  Инициализировать `MistralAIEmbeddings` из `langchain_mistralai.embeddings`.
    2.  Передать в конструктор `api_key` из `app.config.settings` и `model` из константы `MISTRAL_EMBEDDING_MODEL`.
    3.  Этот объект будет выполнять векторизацию через API, не требуя локальных вычислений.
*   **Логика (Альтернативный вариант для локальной разработки):**
    1.  Инициализировать `HuggingFaceEmbeddings` из `langchain_community.embeddings`.
    2.  Передать в конструктор имя модели из константы `HF_EMBEDDING_MODEL_NAME`.

#### **1.3. Инициализация Векторной Базы Данных (ChromaDB)**
*   **Цель:** Создать объект для взаимодействия с векторным хранилищем ChromaDB.
*   **Файл:** `app/core/rag.py`
*   **Логика:** Инициализировать `Chroma` из `langchain_community.vectorstores`. Передать в конструктор:
    *   `persist_directory`: Путь из константы `CHROMA_PERSIST_DIR`.
    *   `embedding_function`: Объект модели эмбеддингов, созданный на предыдущем шаге.
    Это свяжет наше хранилище с функцией векторизации и укажет, где сохранять данные на диске.

---

### **Этап 2: Реализация Логики Индексации**

На этом этапе мы реализуем основную бизнес-логику, которая объединяет все компоненты для создания и наполнения индекса.

#### **2.1. Реализация Функции Загрузки и Разделения Документов**
*   **Цель:** Создать функцию, которая загружает все документы из `knowledge_base` и разбивает их на небольшие, семантически связанные фрагменты (чанки).
*   **Файл:** `app/core/rag.py`
*   **Функция / Сигнатура:** `_load_and_split_documents() -> list[Document]`
*   **Логика:**
    1.  Использовать `DirectoryLoader` из `langchain_community.document_loaders` для загрузки всех файлов из директории `KNOWLEDGE_BASE_DIR`.
    2.  Инициализировать `RecursiveCharacterTextSplitter` из `langchain.text_splitter`, указав оптимальные `chunk_size` (размер чанка) и `chunk_overlap` (перекрытие чанков).
    3.  Вызвать метод `split_documents` у сплиттера, передав ему загруженные документы.
    4.  Вернуть список полученных чанков (объектов `Document`).

#### **2.2. Реализация Основной Функции Индексации**
*   **Цель:** Создать главную функцию, которая оркестрирует весь процесс: загружает документы, разбивает их и сохраняет векторы в ChromaDB.
*   **Файл:** `app/core/rag.py`
*   **Функция / Сигнатура:** `create_vector_store()`
*   **Логика:**
    1.  Вызвать функцию `_load_and_split_documents()` для получения списка чанков.
    2.  Проверить, что список чанков не пуст. Если пуст — вывести информационное сообщение и завершить выполнение.
    3.  Вызвать метод `add_documents` у объекта `Chroma` (созданного на Этапе 1.3), передав ему список чанков. Этот метод автоматически выполнит векторизацию каждого чанка и сохранит результат.
    4.  Добавить логирование для информирования о статусе процесса (начало, количество документов, завершение).

#### **2.3. Создание Точки Входа для Скрипта**
*   **Цель:** Обеспечить возможность запуска процесса индексации как отдельного скрипта из командной строки.
*   **Файл:** `app/core/rag.py`
*   **Логика:**
    1.  Добавить блок `if __name__ == "__main__":`.
    2.  Внутри блока вызвать функцию `create_vector_store()`.
    Это позволит нам выполнять `python -m app.core.rag` для переиндексации базы знаний при обновлении документов.
