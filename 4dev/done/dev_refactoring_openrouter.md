# Рефакторинг для перехода на OpenRouter

## Введение
Этот план описывает последовательность действий для рефакторинга проекта с целью перехода от прямого использования API Mistral AI к использованию агрегатора OpenRouter.
**Цель:**
1.  Устранить проблему с жесткими лимитами бесплатного API Mistral.
2.  Получить доступ к широкому спектру бесплатных и более производительных моделей.
3.  Унифицировать взаимодействие с LLM через OpenAI-совместимый интерфейс.
4.  **Сохранить существующую, кастомную модель для создания эмбеддингов без изменений.**

Разработка будет вестись послойно, затрагивая конфигурацию, слой данных (embeddings) и сервисный слой (LLM).

---

### **Этап 1: Подготовка - Зависимости и Конфигурация**

На этом этапе мы подготовим проект к работе с OpenRouter, обновив зависимости и переменные окружения.

#### **1.1. Обновление `requirements.txt`**
*   **Цель:** Заменить специфичные для Mistral библиотеки на универсальную библиотеку для работы с OpenAI-совместимыми API.
*   **Файл:** `requirements.txt`
*   **Логика:**
    1.  Удалить строки `langchain-mistralai` и `mistralai`.
    2.  Добавить строку `langchain-openai`.
    3.  Итоговая строка: `langchain-openai==0.1.19`.

#### **1.2. Обновление `.env.example`**
*   **Цель:** Отразить в примере файла окружения новые переменные, необходимые для OpenRouter.
*   **Файл:** `.env.example`
*   **Логика:**
    1.  Заменить `MISTRAL_API_KEY` на `OPENROUTER_API_KEY`.
    2.  Добавить комментарии, поясняющие назначение нового ключа.
    3.  Убедиться, что переменная `EMBEDDING_SERVICE_URL` осталась без изменений.
    4.  Добавить опциональные переменные `OPENROUTER_TEMPERATURE` и `OPENROUTER_MAX_TOKENS`.

#### **1.3. Обновление `app/config.py`**
*   **Цель:** Адаптировать Pydantic-модель `Settings` для работы с новыми переменными окружения.
*   **Файл:** `app/config.py`
*   **Класс / Сигнатура:** `class Settings(BaseSettings):`
*   **Логика:**
    1.  Заменить поле `MISTRAL_API_KEY: str` на `OPENROUTER_API_KEY: str`.
    2.  Удалить поле `MISTRAL_CHAT_MODEL`.
    3.  Добавить новые поля с значениями по умолчанию для моделей и базового URL:
        *   `OPENROUTER_CHAT_MODEL: str = "google/gemini-2.0-flash-exp:free"`
        *   `OPENROUTER_API_BASE: str = "https://openrouter.ai/api/v1"`
    4.  Убедиться, что поле `EMBEDDING_SERVICE_URL: str` осталось без изменений.
    5.  Добавить новые поля для управления генерацией: `OPENROUTER_TEMPERATURE: float = 0.7` и `OPENROUTER_MAX_TOKENS: int = 1024`.

---

### **Этап 2: Рефакторинг Сервисного Слоя (LLM)**

#### **2.1. Обновление `app/core/chain.py`**
*   **Цель:** Заменить `ChatMistralAI` на `ChatOpenAI`, настроенный для OpenRouter.
*   **Файл:** `app/core/chain.py`
*   **Функция / Сигнатура:** `get_rag_chain()`
*   **Логика:**
    1.  Удалить импорт `ChatMistralAI`.
    2.  Импортировать `ChatOpenAI` из `langchain_openai`.
    3.  Внутри функции `get_rag_chain` заменить инициализацию `llm`.
        *   **Было:**
            ```python
            llm = ChatMistralAI(mistral_api_key=settings.MISTRAL_API_KEY)
            ```
        *   **Стало:**
            ```python
            llm = ChatOpenAI(
                model=settings.OPENROUTER_CHAT_MODEL,
                openai_api_key=settings.OPENROUTER_API_KEY,
                base_url=settings.OPENROUTER_API_BASE,
                temperature=settings.OPENROUTER_TEMPERATURE,
                max_tokens=settings.OPENROUTER_MAX_TOKENS,
            )
            ```

---

### **Этап 3: Обновление Документации**

На этом этапе мы актуализируем `README.md`, чтобы он отражал изменения в стеке и инструкциях по настройке.

#### **3.1. Обновление `README.md`**
*   **Цель:** Привести документацию в соответствие с новым стеком технологий.
*   **Файл:** `README.md`
*   **Логика:**
    1.  В разделе "Стек технологий" заменить шильдик `Mistral AI` на `OpenRouter`.
    2.  В разделе "Инструкции по запуску" обновить шаг 3 (Настройка переменных окружения), заменив `MISTRAL_API_KEY` на `OPENROUTER_API_KEY` и обновив описание.
    3.  Добавить в пример `.env` новые опциональные переменные `OPENROUTER_TEMPERATURE` и `OPENROUTER_MAX_TOKENS`.

---

### **Этап 4: Тестирование**

*   **Цель:** Убедиться, что после рефакторинга система работает корректно.
*   **Инструкции:**
    1.  Обновить файл `.env`, заменив `MISTRAL_API_KEY` на `OPENROUTER_API_KEY`.
    2.  Выполнить `pip install -r requirements.txt` для установки `langchain-openai==0.1.19` и удаления `langchain-mistralai`.
    3.  Запустить бота командой `python main.py`.
    4.  Проверить работоспособность, задав несколько вопросов боту.
    5.  **Важно:** Переиндексация базы знаний (`python -m app.core.rag`) не требуется, так как модель эмбеддингов не изменялась.
    6.  **Примечание:** В ходе тестирования была выявлена гео-блокировка модели `meta-llama/llama-3.3-8b-instruct:free` и неверный ID для `google/gemini-flash-2.0:free`. Финальная рабочая модель: `google/gemini-2.0-flash-exp:free`.
        *   `model=settings.OPENROUTER_CHAT_MODEL`
        *   `openai_api_key=settings.OPENROUTER_API_KEY`
        *   `base_url=settings.OPENROUTER_API_BASE`

---

### **Этап 4: Обновление Документации**

На этом этапе мы актуализируем `README.md`, чтобы он отражал изменения в стеке и инструкциях по настройке.

#### **4.1. Обновление `README.md`**
*   **Цель:** Привести документацию в соответствие с новым стеком технологий.
*   **Файл:** `README.md`
*   **Логика:**
    1.  В разделе "Стек технологий" заменить шильдик `Mistral AI` на `OpenRouter`.
    2.  В разделе "Инструкции по запуску" обновить шаг 3 (Настройка переменных окружения), заменив `MISTRAL_API_KEY` на `OPENROUTER_API_KEY` и обновив описание.

---

### **Этап 5: Тестирование**

*   **Цель:** Убедиться, что после рефакторинга система работает корректно.
*   **Инструкции:**
    1.  Удалить старую векторную базу `chroma_db/`.
    2.  Выполнить переиндексацию командой `python -m app.core.rag`. Убедиться, что процесс проходит без ошибок.
    3.  Запустить бота командой `python main.py`.

---

### **Этап 6: Реализация механизма фолбэка (Fallback)**

*   **Проблема:** При высокой нагрузке на популярные бесплатные LLM-модели (например, `google/gemini-2.0-flash-exp:free`), API-провайдер возвращает ошибку `429 RateLimitError`, что приводит к сбою в работе бота.
*   **Решение:** Реализовать механизм фолбэка с использованием встроенных средств фреймворка LangChain. Это позволит приложению при возникновении ошибки у основной модели автоматически переключаться на запасную, более стабильную модель, обеспечивая высокую доступность сервиса.

#### **6.1. Обновление `app/config.py`**
*   **Цель:** Добавить в `Settings` поле для fallback-модели.
*   **Логика:**
    1.  В класс `Settings` добавить поле `OPENROUTER_FALLBACK_MODEL: str`.
    2.  В качестве значения по умолчанию указать стабильную, проверенную модель, например, `openai/gpt-oss-20b:free`.

#### **6.2. Обновление `app/core/chain.py`**
*   **Цель:** Интегрировать логику автоматического переключения на запасную модель.
*   **Логика:**
    1.  В функции `get_rag_chain` создать два экземпляра `ChatOpenAI`:
        *   `primary_llm`: Использует основную модель (`settings.OPENROUTER_CHAT_MODEL`).
        *   `fallback_llm`: Использует запасную модель (`settings.OPENROUTER_FALLBACK_MODEL`).
    2.  Объединить их в единый отказоустойчивый `Runnable` с помощью метода `.with_fallbacks()`: `llm = primary_llm.with_fallbacks([fallback_llm])`.
    3.  Использовать этот новый `llm` в основной RAG-цепочке.

---

### **Отчёт для Pull Request**

#### PR: Refactor: Migrate to OpenRouter and Implement Fallback Mechanism

##### Описание

Этот пулл-реквест выполняет стратегический рефакторинг, перенося LLM-провайдера с прямого API Mistral на шлюз OpenRouter. Это изменение решает проблему жестких лимитов, обеспечивает гибкость в выборе моделей и значительно повышает отказоустойчивость приложения за счет реализации механизма фолбэка.

##### Ключевые изменения:

1.  **Миграция на OpenRouter (`app/config.py`, `app/core/chain.py`):**
    *   Зависимость `langchain-mistralai` заменена на `langchain-openai` для поддержки OpenAI-совместимых API.
    *   `ChatMistralAI` заменен на `ChatOpenAI`, настроенный для работы с эндпоинтом OpenRouter.
    *   Конфигурация обновлена для использования `OPENROUTER_API_KEY` и `OPENROUTER_API_BASE`.

2.  **Реализация механизма фолбэка (`app/core/chain.py`, `app/config.py`):**
    *   **Проблема:** Бесплатные и популярные модели часто недоступны из-за `RateLimitError`.
    *   **Решение:** Внедрен механизм отказоустойчивости с использованием `primary_llm.with_fallbacks([fallback_llm])`. Теперь при сбое основной модели система автоматически и прозрачно переключается на запасную, обеспечивая высокую доступность сервиса.
    *   В конфигурацию добавлены переменные `OPENROUTER_CHAT_MODEL` и `OPENROUTER_FALLBACK_MODEL` для гибкого управления основной и запасной моделями.

3.  **Улучшение наблюдаемости (`app/core/chain.py`, `main.py`):**
    *   **Проблема:** Стандартный механизм фолбэка не логирует факт переключения.
    *   **Решение:** Создан кастомный `FallbackLoggingCallbackHandler`, который "слушает" ошибки LLM. При каждом сбое основной модели в лог записывается `WARNING` с деталями ошибки и `INFO` о переключении на запасную модель. Это делает поведение системы полностью прозрачным для мониторинга.

4.  **Стабилизация выбора моделей:**
    *   В ходе тестирования было выявлено, что многие модели (Gemma, Qwen) имеют несовместимый API или нестабильные идентификаторы на OpenRouter.
    *   Финальная конфигурация использует проверенные и стабильные модели от Mistral (`mistralai/mixtral-8x7b-instruct` и `mistralai/mistral-small`), работающие через личный API-ключ для обхода глобальных лимитов OpenRouter.