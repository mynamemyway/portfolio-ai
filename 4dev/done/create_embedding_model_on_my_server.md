# План реализации API-сервиса для модели эмбеддингов

## Этап 0: Инициализация проекта

**Задача:** Подготовить файловую структуру и определить зависимости.

1.  **Создание структуры каталогов:**
    - В корне репозитория создается директория `embedding_service/`.
    - Внутри `embedding_service/` создается директория `app/` для исходного кода.

    ```
    embedding_service/
    ├── app/
    │   ├── __init__.py
    │   ├── main.py         # Код FastAPI приложения
    │   └── models.py       # Pydantic модели для запросов/ответов
    ├── requirements.txt    # Зависимости Python
    └── Dockerfile          # Инструкции для сборки Docker-образа
    ```

2.  **Определение зависимостей:**
    - **Файл:** `embedding_service/requirements.txt`
    - **Логика:** Создать файл и перечислить в нем все необходимые библиотеки:
        - `fastapi`: Веб-фреймворк для создания API.
        - `uvicorn[standard]`: ASGI-сервер для запуска приложения.
        - `sentence-transformers`: Библиотека для загрузки и использования embedding-моделей.
        - `pydantic`: Для валидации данных в API.
        - `python-dotenv`: Для управления переменными окружения (например, выбор модели).

---

## Этап 1: Слой API (Схемы и Роутер)

**Задача:** Спроектировать "контракт" API — как внешние сервисы будут взаимодействовать с нашей функцией векторизации.

1.  **Создание схем Pydantic:**
    - **Файл:** `embedding_service/app/models.py`
    - **Логика:** Определить две Pydantic-модели для строгой типизации и валидации данных на уровне API.
        - `EmbeddingRequest`: Модель для тела входящего `POST`-запроса. Должна содержать поле `texts: List[str]`.
        - `EmbeddingResponse`: Модель для тела ответа. Должна содержать поле `embeddings: List[List[float]]`.

---

## Этап 2: Слой Сервисной Логики и Роутера

**Задача:** Реализовать "мозг" сервиса — загрузку модели и обработку запросов.

1.  **Реализация основной логики в `main.py`:**
    - **Файл:** `embedding_service/app/main.py`
    - **Логика:**
        1.  **Инициализация FastAPI:** Создать экземпляр приложения `app = FastAPI()`.
        2.  **Загрузка модели:** Определить глобальную переменную для хранения модели (например, `embedding_model`). Реализовать логику, которая загружает модель `sentence-transformers` один раз при старте приложения. Это критически важно для производительности, чтобы избежать повторной загрузки тяжелой модели на каждый запрос.
        3.  **Создание эндпоинта:** Реализовать роутер `POST /embed`, который:
            - Принимает в качестве тела запроса объект, соответствующий схеме `EmbeddingRequest`.
            - Использует загруженную модель (`embedding_model.encode(request.texts)`) для векторизации списка текстов.
            - Возвращает объект `EmbeddingResponse` с полученными векторами.

---

## Этап 3: Контейнеризация сервиса с помощью Docker

**Задача:** Подготовить `Dockerfile` для сборки изолированного и переносимого Docker-образа, готового к развертыванию на сервере.

1.  **Написание `Dockerfile`:**
    - **Файл:** `embedding_service/Dockerfile`
    - **Логика:**
        1.  **Базовый образ:** Использовать официальный образ `python:3.12-slim` для минимизации размера.
        2.  **Рабочая директория:** Установить рабочую директорию внутри контейнера (например, `/app`).
        3.  **Установка зависимостей:**
            - Скопировать `requirements.txt` в контейнер.
            - Выполнить `pip install --no-cache-dir -r requirements.txt`. Разделение копирования и установки кэширует этот слой, ускоряя последующие сборки, если зависимости не менялись.
        4.  **Копирование кода:** Скопировать директорию `app/` в рабочую директорию контейнера.
        5.  **Открытие порта:** Указать порт, который будет слушать `uvicorn` (например, `EXPOSE 8000`).
        6.  **Команда запуска:** Определить команду `CMD` для запуска `uvicorn`, которая будет обслуживать FastAPI-приложение. Например: `uvicorn app.main:app --host 0.0.0.0 --port 8000`.