# Сводка Эмбеддинг-Моделей для Документации

Эта таблица содержит сравнение рекомендованных эмбеддинг-моделей с фокусом на их развертывание на CPU-сервере и применимость в различных проектах. Эта документация поможет в будущем принимать решение по выбору модели под конкретную задачу.

## Сравнение Эмбеддинг-Моделей (CPU-Деплой на Intel Core i7-6700 - 64 ГБ RAM)

### Категория: Максимальное качество (Универсальные)

#### 1. `intfloat/multilingual-e5-large`
- **Размер (∼MB / GB):** ∼2.24 GB
- **Размерность вектора:** 1024
- **Ключевая особенность:** Лучшее качество среди универсальных мультиязычных моделей. Отлично работает с русским языком и является гибким стандартом.
- **Рекомендация:** **ОСНОВНОЙ ВЫБОР.** Идеален для старта и для проектов, где требуется максимальная точность понимания запроса.

#### 2. `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- **Размер (∼MB / GB):** ∼1.1 GB
- **Размерность вектора:** 768
- **Ключевая особенность:** Сбалансированный вариант. Хорошее качество для 50+ языков, включая русский. Быстрее, чем `e5-large`.
- **Рекомендация:** **СБАЛАНСИРОВАННЫЙ ВЫБОР.** Хороший компромисс между качеством и скоростью, если `e5-large` окажется слишком медленным для индексации.

---

### Категория: Специализированные (Русский язык)

#### 3. `ai-forever/sbert_large_nlu_ru`
- **Размер (∼MB / GB):** ∼1.3 GB
- **Размерность вектора:** 1024
- **Ключевая особенность:** Максимальная точность и качество для чисто русскоязычных задач (NLU). Специализирован для российского контекста.
- **Рекомендация:** **СПЕЦИАЛИЗАЦИЯ.** Лучший выбор для проектов, сфокусированных исключительно на русском языке, например, для бота-консультанта по продажам.

---

### Категория: Максимальная скорость и легковесность

#### 4. `cointegrated/rubert-tiny2`
- **Размер (∼MB / GB):** ∼115 MB
- **Размерность вектора:** 312
- **Ключевая особенность:** Максимальная скорость при достойном качестве для русского языка. Минимальное потребление RAM.
- **Рекомендация:** **СКОРОСТНОЙ ВЫБОР.** Идеально для приложений, где важен минимальный размер и низкая задержка, а база знаний невелика.

---

### 5. sentence-transformers/all-MiniLM-L6-v2
- **Размер (∼MB / GB):** ∼90 MB
- **Размерность вектора:** 384
- **Ключевая особенность:** Самая быстрая, но англоцентричная.
- **Рекомендация:** НЕ РЕКОМЕНДУЕТСЯ для русскоязычных проектов. Только как запасной вариант для англ. текстов.

---

## Рекомендации по именованию репозиториев

При создании отдельного репозитория для каждого embedding-сервиса рекомендуется использовать ясные и предсказуемые имена, включающие название модели. Это упростит навигацию и управление в будущем.

**Шаблон:** `[model-name]-embedding-service`

**Примеры:**
- `e5-large-embedding-service` (для `intfloat/multilingual-e5-large`)
- `sbert-nlu-ru-embedding-service` (для `ai-forever/sbert_large_nlu_ru`)